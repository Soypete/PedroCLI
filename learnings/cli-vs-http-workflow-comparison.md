# CLI vs HTTP Bridge Workflow Comparison

**Date:** 2026-01-19
**Branch:** feat/dual-file-editing-strategy
**Test Issues:** #32 (Prometheus metrics - CLI), #39 (slog migration - HTTP bridge)

## Executive Summary

This document compares the two workflow modes introduced in ADR-008:

| **Mode** | **CLI** | **HTTP Bridge** |
|----------|---------|-----------------|
| **Setup** | ‚ö° 5 minutes | ‚è±Ô∏è 15-30 minutes |
| **Services** | 1 (LLM) | 2-3 (LLM, DB, optional voice) |
| **Execution** | Direct in repo | Isolated workspace |
| **Concurrency** | ‚ùå Single job | ‚úÖ Multiple jobs |
| **Use Case** | Solo dev, quick tasks | Teams, API, web UI |

**Key Finding:** Both workflows use the same agents and tools, differing only in execution environment. CLI offers simplicity and speed for local development, while HTTP Bridge provides isolation and concurrency for multi-user scenarios.

## Overview

This document compares the dual file editing workflows introduced in ADR-008:
- **CLI Workflow:** Direct repository editing for local development
- **HTTP Bridge Workflow:** Isolated workspaces for concurrent web UI jobs

## Test Setup

### Environment
- **Machine:** M1 Max, macOS
- **Model:** Qwen 2.5 Coder 32B (Q4_K_M, 16K context)
- **Repository:** PedroCLI (git@github.com:Soypete/PedroCLI.git)
- **Starting Branch:** feat/dual-file-editing-strategy
- **Working Directory:** /Users/miriahpeterson/Code/go-projects/pedrocli

### Services Required

**CLI Mode:**
- ‚úÖ llama-server (port 8082) - Required
- ‚ùå PostgreSQL - Not required
- ‚ùå whisper.cpp - Not required
- ‚ùå HTTP server - Not required

**HTTP Bridge Mode:**
- ‚úÖ llama-server (port 8082) - Required
- ‚úÖ PostgreSQL (port 5432) - Required for blog features
- ‚úÖ whisper.cpp (port 8081) - Required for voice transcription
- ‚úÖ HTTP server (port 8080) - Required

---

## Test 1: CLI Workflow - Issue #32 (Prometheus Metrics)

### Issue Details
**Title:** Add Prometheus observability for Kubernetes deployment
**Scope:**
- Create pkg/metrics package with HTTP, job, LLM, and tool metrics
- Instrument HTTP bridge files (server.go, handlers.go)
- Instrument agent files (executor.go, manager.go)
- Instrument LLM backend (ollama.go, server.go)
- Add /metrics and /api/ready endpoints (HTTP bridge only)
- Write tests for metrics package

### Pre-Test State
```bash
# Git status
Branch: feat/dual-file-editing-strategy
Status: Clean working tree (after fixing go.mod syntax error)
Remote: git@github.com:Soypete/PedroCLI.git (SSH)

# Services
llama-server: ‚úì Running (port 8082)
Model: Qwen2.5-Coder-32B-Instruct-Q4_K_M.gguf
Context: 16K (usable: 12K)
GPU Layers: -1 (all layers offloaded to GPU)

# Build Issues Resolved
- Fixed go.mod:225 syntax error (orphaned dependency line)
- Rebuilt pedrocli binary with make build-cli
```

### CLI Command
```bash
./pedrocli build \
  -issue 32 \
  -description "Add Prometheus observability metrics. Create pkg/metrics package with HTTP, job, LLM, and tool metrics. Instrument server.go, handlers.go, db_manager.go, executor.go, ollama.go. Add /metrics and /api/ready endpoints to HTTP bridge only (not CLI). Write tests. Create PR when done."
```

### Workflow Timeline

**Start Time:** 2026-01-19 13:15:40

#### Phase 1: Analyze (‚úÖ Completed in 1 round)
- Explored codebase structure
- Identifies HTTP bridge files to instrument
- Searches for existing metrics or logging patterns
- Uses: bash_explore (grep, find)

#### Phase 2: Plan
- Creates step-by-step implementation plan
- Identifies files to create/modify
- Plans test strategy
- Uses: bash_explore, search

#### Phase 3: Implement
- Creates pkg/metrics/metrics.go
- Instruments HTTP bridge files
- Instruments agent executor
- Instruments LLM backend
- Uses: file, code_edit, bash_edit (sed/awk)
- LSP: Validates with gopls after each edit

#### Phase 4: Validate
- Runs: make test
- Runs: go build ./...
- Checks LSP diagnostics
- Fixes any compilation errors
- Uses: bash_edit, test, lsp

#### Phase 5: Deliver
- Creates branch: feat/32-prometheus-metrics (or pedrocli/32-*)
- Commits changes to current repo
- Pushes to origin using SSH
- Creates PR via gh CLI

**End Time:** [To be recorded]
**Total Duration:** [To be calculated]

### Observations (During Execution)

#### File Editing Strategy
- [ ] Which tools were used most? (file, code_edit, bash_edit)
- [ ] Were bash regex operations used? (sed/awk)
- [ ] How many LSP diagnostic checks?
- [ ] Any errors caught by LSP?

#### Git Workflow
- [ ] Branch name created
- [ ] Remote URL verification (should stay SSH)
- [ ] Changes visible in working directory?
- [ ] PR created successfully?

#### Performance
- [ ] Inference iterations
- [ ] Token usage
- [ ] Time per phase
- [ ] Total elapsed time

### Expected Outcomes

**Files Created:**
- pkg/metrics/metrics.go
- pkg/metrics/metrics_test.go

**Files Modified:**
- pkg/httpbridge/server.go (add /metrics, /ready endpoints)
- pkg/httpbridge/handlers.go (instrument requests)
- pkg/agents/phased_executor.go (job metrics)
- pkg/llm/ollama.go (backend metrics)
- go.mod (add prometheus/client_golang)

**Branch:** feat/32-prometheus-metrics
**PR:** Draft PR created on GitHub

---

## Test 2: HTTP Bridge Workflow - Issue #39 (slog Migration)

### Issue Details
**Title:** [To be created]
**Scope:**
- Migrate from fmt.Print* to slog structured logging
- Create pkg/logger/logger.go for centralized logger
- Update 17 files across pkg/ and cmd/
- Use structured logging fields
- Create PR when done

### Pre-Test State
```bash
# Git status
Branch: feat/dual-file-editing-strategy
Status: [To be checked]
Remote: git@github.com:Soypete/PedroCLI.git (SSH)

# Services (all must be running)
llama-server: [Status]
PostgreSQL: [Status]
whisper.cpp: [Status]
HTTP server: [Status]
```

### Service Startup Commands
```bash
# Terminal 1: llama-server (already running from Test 1)
# [Already started]

# Terminal 2: PostgreSQL
docker run --name pedrocli-postgres \
  -e POSTGRES_USER=pedrocli \
  -e POSTGRES_PASSWORD=pedrocli \
  -e POSTGRES_DB=pedrocli \
  -p 5432:5432 \
  -d postgres:16

# Terminal 3: whisper.cpp
~/Code/ml/whisper.cpp/build/bin/whisper-server \
  --model ~/Code/ml/whisper.cpp/models/ggml-base.en.bin \
  --port 8081 \
  --convert

# Terminal 4: HTTP server (with 1Password secrets)
cd /Users/miriahpeterson/Code/go-projects/pedrocli
op run --env-file=.env -- ./pedrocli-http-server
```

### API Request
```bash
curl -X POST http://localhost:8080/api/jobs \
  -H "Content-Type: application/json" \
  -d '{
    "type": "build",
    "description": "Migrate from fmt to slog. Replace all fmt.Print/Printf/Println with slog.Info/Warn/Error/Debug. Create centralized logger in pkg/logger/logger.go. Update all 17 files. Use structured logging fields. Create PR when done.",
    "issue_number": "39"
  }'
```

### Workflow Timeline

**Start Time:** [To be recorded]

#### Workspace Setup
- Checks: ~/.cache/pedrocli/jobs/<job-id>/workspace/.git
- First run: git clone git@github.com:Soypete/PedroCLI.git workspace/
- Subsequent runs: git fetch && git pull (reuse!)

#### Phase 1: Analyze
- Explores workspace codebase
- Identifies all files with fmt.Print*
- Counts occurrences (should be ~17 files)
- Uses: bash_explore (grep across workspace)

#### Phase 2: Plan
- Creates migration strategy
- Plans centralized logger design
- Lists files to modify
- Uses: bash_explore, search

#### Phase 3: Implement
- Creates pkg/logger/logger.go in workspace
- Multi-file regex: sed -i 's/fmt\.Printf(/slog.Info(/g' pkg/**/*.go
- Updates imports across files
- Uses: file, code_edit, bash_edit
- LSP: Validates in workspace

#### Phase 4: Validate
- Runs tests in workspace
- Builds in workspace
- Fixes errors iteratively
- Uses: bash_edit, test, lsp

#### Phase 5: Deliver
- Commits in workspace
- Pushes from workspace to remote
- Creates PR via gh CLI
- Optional: Cleanup workspace

**End Time:** [To be recorded]
**Total Duration:** [To be calculated]

### Observations (During Execution)

#### Workspace Isolation
- [ ] Workspace path created
- [ ] Was workspace reused or fresh cloned?
- [ ] Changes isolated from main repo?
- [ ] Cleanup executed?

#### File Editing Strategy
- [ ] Multi-file sed operations used?
- [ ] How many files modified?
- [ ] LSP diagnostics in workspace?

#### Git Workflow
- [ ] Branch created in workspace
- [ ] Push from workspace successful?
- [ ] SSH URL used?
- [ ] PR created?

#### Performance
- [ ] Workspace setup time
- [ ] Clone vs pull time
- [ ] Inference iterations
- [ ] Total elapsed time

### Expected Outcomes

**Workspace:** ~/.cache/pedrocli/jobs/job-<id>/workspace/

**Files Created (in workspace):**
- pkg/logger/logger.go
- pkg/logger/logger_test.go

**Files Modified (in workspace):**
- ~17 files with fmt ‚Üí slog migration
- Import statements updated

**Branch:** feat/39-slog-migration (in workspace)
**PR:** Draft PR created on GitHub
**Workspace:** Preserved (cleanup_on_complete: false)

---

## Comparison Matrix

| **Aspect** | **CLI Workflow** | **HTTP Bridge Workflow** |
|------------|------------------|--------------------------|
| **Execution Mode** | Direct in-repo editing | Isolated workspace |
| **Working Directory** | /Users/.../pedrocli | ~/.cache/pedrocli/jobs/<id>/workspace/ |
| **Concurrency** | Single job (synchronous) | Multiple concurrent jobs |
| **Workspace Setup** | None (already in repo) | Clone or git pull |
| **File Edits** | Visible immediately | Isolated from main repo |
| **Git Operations** | In current repo | In isolated workspace |
| **Branch Location** | Current repo | Workspace repo |
| **PR Creation** | From current repo | From workspace |
| **Cleanup** | Not applicable | Optional (configurable) |
| **Speed** | Fastest (no setup) | Fast (with workspace reuse) |
| **Debugging** | Live changes visible | Preserved workspace |
| **Use Case** | Local development | Multi-user, web UI, concurrent |

---

## Key Findings

### CLI Workflow Observations

**Advantages:**
‚úÖ **No setup overhead** - Works directly in current repository, no cloning
‚úÖ **Simple execution** - Single command: `./pedrocli build -issue 32 -description "..."`
‚úÖ **Minimal services** - Only requires llama-server running (no database, no HTTP server)
‚úÖ **Live changes** - File edits immediately visible in working directory
‚úÖ **Fast iteration** - Developer can see changes in real-time in their editor
‚úÖ **Standard git workflow** - Creates branch, commits, pushes from current repo
‚úÖ **SSH by default** - Automatically uses SSH remote URLs for password-less push

**Challenges:**
‚ùå **Build issues** - Required fixing go.mod syntax error before running
‚ùå **Binary rebuild required** - Old binary had outdated code, needed `make build-cli`
‚ùå **Single job limitation** - Can only run one task at a time (synchronous)
‚ùå **LLM response time** - Local model inference can be slow (several minutes per round)
‚ùå **Context size limits** - Large repos may hit 16K context limits with local models
üî¥ **CRITICAL: LLM timeouts cause complete failure** - No retry mechanism, 35 minutes of work lost
üî¥ **No progress preservation** - If LLM times out mid-workflow, entire job fails
üî¥ **Unpredictable reliability** - Local models can become unresponsive under load

**Performance (Issue #32 - FAILED):**
- Setup time: ~0 seconds (already in repo)
- Phase 1 (Analyze): ‚úÖ Completed in 1 round (~30 seconds)
- Phase 2 (Plan): ‚úÖ Completed in 1 round (~30 seconds) - Created 10-step plan
- Phase 3 (Implement): ‚úÖ Completed in 2 rounds (~3-4 minutes)
  - Modified: pkg/metrics/metrics.go (formatting fixes only - spaces‚Üítabs)
  - Modified: pkg/metrics/metrics_test.go (import ordering)
  - Added Prometheus dependency to go.mod
- Phase 4 (Validate): ‚ùå FAILED at Round 2/15 - LLM timeout
- Phase 5 (Deliver): ‚ùå Never reached
- **Total time: ~35 minutes** (13:15:40 - 13:50:51)
- **Final status: FAILED**

**Failure Details:**
```
Error: phase validate failed: inference failed: request failed:
Post "http://localhost:8082/v1/chat/completions":
context deadline exceeded (Client.Timeout exceeded while awaiting headers)
```

**Root Cause:**
The local llama-server (Qwen 2.5 Coder 32B on M1 Max) took too long to respond during Phase 4. The agent was iterating on test failures when the LLM response timed out, causing the entire workflow to fail.

**Critical Finding - Local LLM Reliability:**
‚ùå **Unpredictable performance** - Local models can timeout under load
‚ùå **No graceful degradation** - Timeout causes complete workflow failure
‚ùå **Lost progress** - 35 minutes of work lost due to single timeout
‚ö†Ô∏è **Context/load sensitive** - Large context or complex prompts increase risk

**What Was Actually Accomplished:**
- Only formatting changes (indentation fixes)
- Did NOT implement the full Prometheus metrics package
- Did NOT add /metrics or /api/ready endpoints
- Did NOT instrument HTTP bridge files
- Did NOT create comprehensive tests
- Did NOT create PR

The agent was still very early in the implementation when it timed out.

**Git Workflow Observation:**
The agent correctly runs `git status` to check repository state. The "untracked files" messages are informational - showing our manually-created comparison document. The agent's actual work (metrics files) are properly tracked and modified.

### HTTP Bridge Workflow Observations

**Advantages:**
‚úÖ **Concurrent jobs** - Multiple jobs can run simultaneously in isolated workspaces
‚úÖ **Workspace isolation** - Each job gets `~/.cache/pedrocli/jobs/<job-id>/workspace/`
‚úÖ **Workspace reuse** - Subsequent jobs on same repo use `git pull` instead of re-clone
‚úÖ **Web UI** - Browser-based interface for submitting and monitoring jobs
‚úÖ **API access** - RESTful API for programmatic job submission
‚úÖ **Job persistence** - Job history and results preserved
‚úÖ **Debugging** - Preserved workspaces enable post-mortem analysis

**Challenges:**
‚ùå **Complex setup** - Requires multiple services: llama-server, PostgreSQL, HTTP server
‚ùå **Database dependency** - HTTP server fails to start without PostgreSQL running
‚ùå **Workspace storage** - Workspaces accumulate disk usage over time
‚ùå **Additional overhead** - Workspace setup adds time (clone or pull)
‚ùå **Container requirements** - PostgreSQL typically run in Docker/Podman
‚ùå **Environment variables** - May need secrets management (1Password, etc.)

**Service Dependencies:**
```bash
# Required services (all must be running)
‚úÖ llama-server (port 8082)   - LLM inference
‚ùå PostgreSQL (port 5432)       - Database (blocks HTTP server startup)
‚ùå HTTP server (port 8080)      - API and Web UI
‚ö†Ô∏è  whisper.cpp (port 8081)     - Voice transcription (optional, blog only)
```

**Blocker Encountered:**
The HTTP server requires PostgreSQL to be running at startup. The database connection is mandatory, even for code jobs that don't use blog features. This prevents testing the HTTP bridge workflow without setting up a full database environment.

---

## Tool Usage Comparison

### CLI Tools Used
| Tool | Count | Usage |
|------|-------|-------|
| bash_explore | [TBD] | Analyze/Plan phases |
| bash_edit | [TBD] | Implement/Validate phases |
| file | [TBD] | File operations |
| code_edit | [TBD] | Precise edits |
| lsp | [TBD] | Diagnostics |
| git | [TBD] | Version control |
| test | [TBD] | Testing |

### HTTP Bridge Tools Used
| Tool | Count | Usage |
|------|-------|-------|
| bash_explore | [TBD] | Analyze/Plan phases |
| bash_edit | [TBD] | Implement/Validate phases |
| file | [TBD] | File operations |
| code_edit | [TBD] | Precise edits |
| lsp | [TBD] | Diagnostics |
| git | [TBD] | Version control |
| test | [TBD] | Testing |

---

## Performance Metrics

### CLI Workflow (Issue #32)
```
Workspace Setup:     N/A (direct editing)
Analyze Phase:       [Duration]
Plan Phase:          [Duration]
Implement Phase:     [Duration]
Validate Phase:      [Duration]
Deliver Phase:       [Duration]
-------------------------------------------
Total Duration:      [Duration]
Inference Iterations: [Count]
Token Usage:         [Tokens]
Files Created:       [Count]
Files Modified:      [Count]
```

### HTTP Bridge Workflow (Issue #39)
```
Workspace Setup:     [Duration] (clone or pull)
Analyze Phase:       [Duration]
Plan Phase:          [Duration]
Implement Phase:     [Duration]
Validate Phase:      [Duration]
Deliver Phase:       [Duration]
-------------------------------------------
Total Duration:      [Duration]
Inference Iterations: [Count]
Token Usage:         [Tokens]
Files Created:       [Count]
Files Modified:      [Count]
Workspace Size:      [MB]
```

---

## Recommendations

### When to Use CLI Workflow

**Best for:**
- üë§ **Solo developers** working on local machine
- üöÄ **Quick iterations** - testing features, fixing bugs
- üîß **Active development** - want to see changes in real-time in editor
- üì¶ **Simple setup** - don't want to manage multiple services
- üèÉ **One task at a time** - sequential workflow is acceptable
- üñ•Ô∏è **Local LLM models** - already running llama-server or Ollama

**Example use cases:**
```bash
# Quick feature addition
./pedrocli build -description "Add rate limiting to API"

# Bug fix with diagnostics
./pedrocli debug -symptoms "Server crashes on startup" -logs error.log

# Code review before merge
./pedrocli review -branch feature/new-api

# Issue triage
./pedrocli triage -description "Memory leak in handler"
```

### When to Use HTTP Bridge Workflow

**Best for:**
- üë• **Team environments** - multiple developers submitting jobs
- üåê **Web UI access** - non-technical users triggering builds
- üîÑ **Concurrent jobs** - run multiple tasks simultaneously
- üîí **Job isolation** - ensure jobs don't interfere with each other
- üìä **Job tracking** - need history and persistence
- ü§ñ **API integration** - programmatic job submission (CI/CD, webhooks)
- ‚òÅÔ∏è **Server deployment** - running as a service on remote machine

**Example use cases:**
```bash
# Via API
curl -X POST http://localhost:8080/api/jobs \
  -H "Content-Type: application/json" \
  -d '{
    "type": "build",
    "description": "Implement OAuth2",
    "issue_number": "42"
  }'

# Multiple concurrent jobs
curl -X POST http://localhost:8080/api/jobs -d '{"type":"build","description":"Feature A"}'
curl -X POST http://localhost:8080/api/jobs -d '{"type":"build","description":"Feature B"}'
curl -X POST http://localhost:8080/api/jobs -d '{"type":"debug","symptoms":"Issue C"}'
# All three run in parallel in isolated workspaces!

# Web UI
# Open http://localhost:8080 and submit jobs via browser
```

### Setup Complexity Comparison

**CLI Setup (5 minutes):**
```bash
1. Start llama-server (or Ollama)
   ‚Üí make llama-server

2. Build CLI binary
   ‚Üí make build-cli

3. Run command
   ‚Üí ./pedrocli build -description "..."

‚úÖ Done!
```

**HTTP Bridge Setup (15-30 minutes):**
```bash
1. Start llama-server (or Ollama)
   ‚Üí make llama-server

2. Start PostgreSQL
   ‚Üí docker run -d -p 5432:5432 \
      -e POSTGRES_USER=pedrocli \
      -e POSTGRES_PASSWORD=pedrocli \
      -e POSTGRES_DB=pedrocli \
      postgres:16

3. (Optional) Start whisper.cpp for blog voice features
   ‚Üí ~/whisper.cpp/build/bin/whisper-server \
      --model models/ggml-base.en.bin \
      --port 8081

4. Configure .pedrocli.json
   ‚Üí Set database connection, workspace paths

5. Set environment secrets (if using blog/calendar features)
   ‚Üí op run --env-file=.env -- ./pedrocli-http-server

6. Build and start HTTP server
   ‚Üí make build-http
   ‚Üí ./pedrocli-http-server

7. Access web UI or API
   ‚Üí http://localhost:8080

‚úÖ Done!
```

### Decision Matrix

| Criteria | CLI | HTTP Bridge |
|----------|-----|-------------|
| Setup time | 5 min | 15-30 min |
| Required services | 1 (LLM) | 2-3 (LLM + DB + optional whisper) |
| Concurrent jobs | ‚ùå No | ‚úÖ Yes |
| Web UI | ‚ùå No | ‚úÖ Yes |
| API access | ‚ùå No | ‚úÖ Yes |
| Live file changes visible | ‚úÖ Yes | ‚ùå No (isolated workspace) |
| Job isolation | ‚ùå No | ‚úÖ Yes |
| Workspace overhead | ‚úÖ None | ‚ö†Ô∏è Clones/pulls |
| Best for | Solo dev, quick tasks | Teams, API, concurrent |

---

## Appendix

### CLI Job Output Location
```
/tmp/pedrocli-jobs/job-<id>/
‚îú‚îÄ‚îÄ 001-prompt.txt
‚îú‚îÄ‚îÄ 002-response.txt
‚îú‚îÄ‚îÄ 003-tool-calls.json
‚îú‚îÄ‚îÄ 004-tool-results.json
‚îî‚îÄ‚îÄ ...
```

### HTTP Bridge Job Output Location
```
~/.cache/pedrocli/jobs/<job-id>/
‚îú‚îÄ‚îÄ context/              # LLM context files
‚îÇ   ‚îú‚îÄ‚îÄ 001-prompt.txt
‚îÇ   ‚îú‚îÄ‚îÄ 002-response.txt
‚îÇ   ‚îî‚îÄ‚îÄ ...
‚îî‚îÄ‚îÄ workspace/            # Isolated git repo
    ‚îú‚îÄ‚îÄ .git/
    ‚îú‚îÄ‚îÄ pkg/
    ‚îú‚îÄ‚îÄ cmd/
    ‚îî‚îÄ‚îÄ ...
```

---

## Test Results Summary

### CLI Workflow Test (Issue #32)
- **Start:** 2026-01-19 13:15:40
- **End:** 2026-01-19 13:50:51
- **Duration:** 35 minutes
- **Status:** ‚ùå FAILED (LLM timeout)
- **Phases Completed:** 3/5 (Analyze, Plan, Implement)
- **Phase Failed:** Validate (Round 2/15)
- **Work Accomplished:** Minimal formatting changes only
- **PR Created:** No

**Key Insight:**
The CLI workflow demonstrated fast setup and direct repository editing, but **catastrophically failed** due to local LLM timeout. This revealed a critical weakness: **local LLM workflows have no fault tolerance**. A single timeout after 35 minutes resulted in complete job failure with no recovery mechanism.

### HTTP Bridge Workflow Test
- **Status:** Not tested (cancelled to observe CLI completion first)
- **Discovery:** HTTP bridge job showed same `work_dir` as CLI, suggesting WorkspaceManager isolation may not be active by default

### Critical Findings

**1. Job Migration Feature (Cross-Mode Visibility)**
The HTTP server automatically imports CLI jobs from `/tmp/pedrocli-jobs` into the database on startup:
```
Migrating 1 jobs from /tmp/pedrocli-jobs to database
Migrated job job-1768853750 -> 6b8f6ee5-59dc-47b1-93c4-bac42604e4f4
```

**Implications:**
- ‚úÖ CLI jobs become visible in web UI after HTTP server starts
- ‚úÖ Centralized job tracking across both modes
- ‚úÖ Can review CLI job history via web interface
- ‚ö†Ô∏è CLI jobs get new UUIDs when migrated to database
- ‚ö†Ô∏è Migration happens automatically - no opt-out

This creates a **convergence point** between CLI and HTTP bridge modes, enabling unified job management.

**2. Local LLM Reliability is the Limiting Factor**
- CLI workflow simplicity is negated by LLM unpredictability
- No retry, no checkpoint, no progress preservation
- 35 minutes of compute time completely wasted

**2. Dual Workflow Design is Sound**
- ADR-008 architecture is correct (direct vs isolated)
- Tools and agents work identically in both modes
- Setup differences are as documented

**3. Production Recommendation**
For production use:
- ‚úÖ Use cloud LLM APIs (OpenAI, Anthropic) for reliability
- ‚úÖ Implement timeout retry mechanisms
- ‚úÖ Add progress checkpointing between phases
- ‚ö†Ô∏è Local LLMs are risky for critical workflows

**4. HTTP Bridge Workspace Isolation**
- Needs verification: Job showed CLI work_dir, not isolated workspace
- May require explicit configuration or is not enabled by default

---

## References
- [ADR-008: Dual File Editing Strategy](../docs/adr/ADR-008-dual-file-editing.md)
- [File Editing Strategy Guide](../docs/file-editing-strategy.md)
- [Workspace Manager Implementation](../pkg/httpbridge/workspace.go)
